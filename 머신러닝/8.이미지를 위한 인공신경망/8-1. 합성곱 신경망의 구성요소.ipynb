{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9f4aea",
   "metadata": {},
   "source": [
    "### 합성곱\n",
    "합성곱 convolution 은 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.\n",
    "- 각 특성에 ***뉴런(합성곱층의 뉴런)*** 의 가중치(w)를 곱하고 절편 더하기 -> 1개의 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ec332",
   "metadata": {},
   "source": [
    "ex) 가중치 w1~w3와 절편 b를 가지고 특성 3개씩 모아서 가중치 * 특성 + 절편으로 하나의 출력으로 만든다(10개 특성으로 8개 출력)\n",
    "\n",
    "\n",
    "- 밀집층의 뉴런은 입력 개수만큼 10개의 가중치를 가지고 1개 출력 만듦\n",
    "- 합성곱층은 3개 특성 가지고 8개 출력을 만듦\n",
    "- 합성곱층의(뉴런) 가중치 개수는 정하기 나름이다 ( **하이퍼파라미터** )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a759bd6",
   "metadata": {},
   "source": [
    "이전에 그렸던 신경망 층의 그림은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결되어 있다. 그런데 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 때문에 이런 식으로 표현하기가 어렵다. 또 뉴런이라고 부르기도 어색하다. \n",
    "\n",
    "합성곱 신경망 convolutional neural network,CNN에서는 완전 연결 신경망과 달리 뉴런을 **필터 filter** 라고 부른다. 혹은 **커널 kernel** 이라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b14c74",
   "metadata": {},
   "source": [
    "완전 연결 신경망?\n",
    "- 7장에서 만든 신경망. 완전 연결층(밀집층)만 사용하여 만든 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56939d0f",
   "metadata": {},
   "source": [
    "여기선 케라스 API 와 이름을 맞추어 뉴런 개수를 얘기할 땐 **필터**\n",
    "\n",
    "입력에 곱해지는 가중치를 의미할 떄는 **커널** 이라고 부르겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0857757",
   "metadata": {},
   "source": [
    "#### 글이 많아서 자세한 내용 및 설명은 책으로(p.423~)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c9449",
   "metadata": {},
   "source": [
    "**특성 맵** : 합성곱 계산을 통해 얻은 출력들 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c61816",
   "metadata": {},
   "source": [
    "### 케라스 합성곱 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc12c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c177d550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd4499",
   "metadata": {},
   "source": [
    "1. 첫번째 매개변수는 **필터(도장)의 개수**\n",
    "2. 두번째는 **필터에 사용할 커널의 크기** -> 가중치 크기\n",
    "\n",
    "필터의 개수와 커널의 크기는 반드시 지정해야함\n",
    "\n",
    "3. 마지막은 밀집층에서와 같이 활성화 함수를 지정해준다\n",
    "\n",
    "보통 커널 크기는 (3,3), (5,5)로 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b7ce0",
   "metadata": {},
   "source": [
    "케라스 API를 사용하면 합성곱 층을 사용하는 것이 어렵지 않다. 이전에 Dense 층을 사용했던 자리에 대신 Conv2D층을 넣으면 된다. 다만 kernel_size와 같이 추가적인 매개변수들을 고려해야 한다.\n",
    "\n",
    "그렇다면 합성곱 신경망의 정의는 무엇일까? 일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라고 부른다. ***즉 꼭 합성곱 층만 사용한 신경을 합성곱 신경망이라고 부르는 것이 아니다.*** \n",
    "\n",
    "이전 장에서 보았듯이 클래스에 대한 확률을 계산하려면 마지막 층에 클래스 개수만큼의 뉴런을 가진 밀집층을 두는 것이 일반적이니깐..\n",
    "\n",
    "좋다. 합성곱 층이 구현된 케라스 API를 잠시 살펴보았다. 그런데 합성곱 신경망을 실제 만들려면 조금 더 알아야 할 것이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0ba9b",
   "metadata": {},
   "source": [
    "### 패딩과 스트라이드\n",
    "\n",
    "앞에서 예로 들었던 합성곱 계산은 (4,4) 크기의 입력에 (3,3)크기의 커널을 작용하여 (2,2) 크기의 특성 **맵(필터 하나로 4개 출력)** 을 만들었다. 그런데 만약 커널 크기는 (3,3)으로 그대로 두고 출력의 크기를 입력과 동일하게 (4,4)로 만들려면 어떻게 해야 할까?\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "(4,4) 입력과 동일한 크기의 출력을 만들려면 마치 더 큰 입력에 합성곱하는 척해야 한다. 예를 들어 실제 입력 크기는 (4,4)이지만 (6,6)처럼 다룬다고 가정해 보자. 오른쪽 그림과 같이 (6,6) 크기이면 (3,3) 크기의 커널로 합성곱을 했을 때 출력의 크기가 얼마나 될까?\n",
    "- (3,3) 커널로 도장을 찍어 보면 출력의 크기가 (4,4)가 된다.\n",
    "\n",
    "\n",
    "이렇게 입력 배열의 주위를 가상의 원소로 채우는 것은 **패딩(padding)** 이라고 한다. ***실제 입력값이 아니기 때문에 패딩은 0으로 채운다.*** 즉 (4,4)크기의 입력에 0을 1개 패딩 하면 다음과 같은 (6,6) 크기의 입력이 된다. 패딩의 역할은 순전히 커널이 도장을 찍을 횟수를 늘려주는 것 밖에는 없다. ***실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지는 않는다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7f497",
   "metadata": {},
   "source": [
    "이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 ***입력 주위에 0으로 패딩 하는 것을 세임 패딩 (same padding)이라고 부른다.*** 합성곱 신경망에서는 세임 패딩이 많이 사용된다. 바꿔 말하면 입력과 특성 맵의 크기를 동일하게 만드는 경우가 아주 많다.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "***패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 밸리드 패딩(valid padding)이라고 한다.*** 밸리드 패딩은 특성 맵의 크기가 줄어들 수밖에 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152af62",
   "metadata": {},
   "source": [
    "\n",
    "그럼 왜 합성곱에서는 패딩을 즐겨 사용할까? 만약 패딩이 없다면 위의 예에서 (4,4) 크기의 입력에 패딩 없이 합성곱을 한다면 왼쪽 위 모서리의 3은 커널 도장에서 딱 한번 찍힌다. **사실 네 모서리에 있는 다른 3개의 값도 마찬가지로 한 번만 찍힘.**\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "반면 다른 원소들은 2번 이상 커널과 계산된다. 가운데 있는 4개 원소 4,8,5,1은 4번의 합성곱 계산에 모두 포한된다. 만약 이 입력을 이미지라고 생각하면 **모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 가능성이 높다.** 반면 가운데 있는 정보는 두드러지게 표현된다.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "적절한 패딩은 이처럼 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와준다. 앞에서도 언급했지만 일반적인 합성곱 신경망에서는 ***세임 패딩이 많이 사용된다.*** 케라스 Conv2D 클래스에서는 padding 매개변수로 패딩을 지정할 수 있다. \n",
    "\n",
    "기본값은 'valid'로 밸리드 패딩을 나타낸다. 세임 패딩을 사용하려면 'same'으로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1653bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c2294e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24779f",
   "metadata": {},
   "source": [
    "##### 스트라이드\n",
    "- 여태 본 합성곱은 좌우, 상하로 한 칸씩만 이동함\n",
    "\n",
    "- 하지만 두 번 건너뛸 수도 있다\n",
    "\n",
    "- 이렇게 하면 만들어지는 특성맵의 크기는 더 작아진다.\n",
    "\n",
    "- 기본값 = 1(한칸씩), 하지만 strides 매개변수를 조정하면 바꿀 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081519f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c24ebbd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same', strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f948c",
   "metadata": {},
   "source": [
    "strides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1,1)과 같이 튜플을 사용해 각각 지정할 수 있다.\n",
    "\n",
    "하지만 커널의 이동 크기를 가로세로 방향으로 다르게 지정하는 경우는 거의 없다. \n",
    "\n",
    "또 1보다 큰 스트라이드를 사용하는 경우도 드물다. ***대부분 기본값을 그대로 사용하기 때문에 strides 매개변수는 잘 사용하지 않는다.***\n",
    "\n",
    "스트라이드는 도장(필터)이 이동하는 칸의 개수라고 생각하면 편하다. 튜플로 이동 칸수를 지정할 수 있다.\n",
    "\n",
    "\n",
    "케라스 API를 사용하면 Conv2D 클래스의 옵션으로 간단히 처리 할 수 있다. ***꼭 기억해야 할 것은 세임 패딩의 경우 입력과 만들어진 특성 맵의 가로세로 크기가 같다는 점이다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0cf43",
   "metadata": {},
   "source": [
    "### 폴링\n",
    "폴링(pooling)은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. ***하지만 특성맵의 개수는 줄이지 않는다.***\n",
    "\n",
    "예를 들면 다음 그림처럼 (2,2,3) 크기의 특성 맵에 풀링을 적용하면 마지막 차원인 개수는 그대로 유지하고 너비와 높이만 줄어들어 (1,1,3)크기의 특성 맵이 된다.(p.435)\n",
    "\n",
    "폴링은 특성 맵에 커널 없는 필터를 적용하는 것과 비슷하게 생각하자.\n",
    "폴링도 합성곱처럼 입력 위를 지나가면서 도장을 찍는다. 이를 각각 최대 풀링 maxpooling 과 평균 풀링 average pooling 이라고 부른다. 풀링은 합성곱 층과 뚜렷이 구분되기 때문에 풀링 층이라고 부른다.\n",
    "\n",
    "풀링 층의 출력도 특성 맵이라고 해야하나?\n",
    "\n",
    "맞다. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값을 모두 특성 맵이라고 부른다.\n",
    "스트라이드는 이동의 크기\n",
    "\n",
    "풀링은 가중치가 없고 크기와 스트라이드가 같기 때문에 이해하기 쉽다. 또 패딩도 없다. 케라스에서 MaxPooling2D 클래스로 풀링을 수행할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
