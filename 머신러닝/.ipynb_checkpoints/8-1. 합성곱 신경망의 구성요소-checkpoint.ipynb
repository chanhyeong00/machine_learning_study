{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad9abd8",
   "metadata": {},
   "source": [
    "### 합성곱\n",
    "합성곱 convolution 은 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만 드러나게 하는 것으로 비유할 수 있다.\n",
    "- 각 특성에 ***뉴런(합성곱층의 뉴런)*** 의 가중치(w)를 곱하고 절편 더하기 -> 1개의 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccdfe1",
   "metadata": {},
   "source": [
    "ex) 가중치 w1~w3와 절편 b를 가지고 특성 3개씩 모아서 가중치 * 특성 + 절편으로 하나의 출력으로 만든다(10개 특성으로 8개 출력)\n",
    "\n",
    "\n",
    "- 밀집층의 뉴런은 입력 개수만큼 10개의 가중치를 가지고 1개 출력 만듦\n",
    "- 합성곱층은 3개 특성 가지고 8개 출력을 만듦\n",
    "- 합성곱층의(뉴런) 가중치 개수는 정하기 나름이다 ( **하이퍼파라미터** )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe92c1c",
   "metadata": {},
   "source": [
    "이전에 그렸던 신경망 층의 그림은 뉴런이 길게 늘어서 있고 서로 조밀하게 연결되어 있다. 그런데 합성곱에서는 뉴런이 입력 위를 이동하면서 출력을 만들기 때문에 이런 식으로 표현하기가 어렵다. 또 뉴런이라고 부르기도 어색하다. \n",
    "\n",
    "합성곱 신경망 convolutional neural network,CNN에서는 완전 연결 신경망과 달리 뉴런을 **필터 filter** 라고 부른다. 혹은 **커널 kernel** 이라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a23e6",
   "metadata": {},
   "source": [
    "완전 연결 신경망?\n",
    "- 7장에서 만든 신경망. 완전 연결층(밀집층)만 사용하여 만든 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b99ea",
   "metadata": {},
   "source": [
    "여기선 케라스 API 와 이름을 맞추어 뉴런 개수를 얘기할 땐 **필터**\n",
    "\n",
    "입력에 곱해지는 가중치를 의미할 떄는 **커널** 이라고 부르겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b3dde",
   "metadata": {},
   "source": [
    "#### 글이 많아서 자세한 내용 및 설명은 책으로(p.423~)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fbbae",
   "metadata": {},
   "source": [
    "**특성 맵** : 합성곱 계산을 통해 얻은 출력들 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a388442",
   "metadata": {},
   "source": [
    "### 케라스 합성곱 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23218a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c177d550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197cf4b",
   "metadata": {},
   "source": [
    "1. 첫번째 매개변수는 **필터(도장)의 개수**\n",
    "2. 두번째는 **필터에 사용할 커널의 크기** -> 가중치 크기\n",
    "\n",
    "필터의 개수와 커널의 크기는 반드시 지정해야함\n",
    "\n",
    "3. 마지막은 밀집층에서와 같이 활성화 함수를 지정해준다\n",
    "\n",
    "보통 커널 크기는 (3,3), (5,5)로 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b0d669",
   "metadata": {},
   "source": [
    "케라스 API를 사용하면 합성곱 층을 사용하는 것이 어렵지 않다. 이전에 Dense 층을 사용했던 자리에 대신 Conv2D층을 넣으면 된다. 다만 kernel_size와 같이 추가적인 매개변수들을 고려해야 한다.\n",
    "\n",
    "그렇다면 합성곱 신경망의 정의는 무엇일까? 일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라고 부른다. ***즉 꼭 합성곱 층만 사용한 신경을 합성곱 신경망이라고 부르는 것이 아니다.*** \n",
    "\n",
    "이전 장에서 보았듯이 클래스에 대한 확률을 계산하려면 마지막 층에 클래스 개수만큼의 뉴런을 가진 밀집층을 두는 것이 일반적이니깐..\n",
    "\n",
    "좋다. 합성곱 층이 구현된 케라스 API를 잠시 살펴보았다. 그런데 합성곱 신경망을 실제 만들려면 조금 더 알아야 할 것이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c1ea7",
   "metadata": {},
   "source": [
    "### 패딩과 스트라이드\n",
    "\n",
    "앞에서 예로 들었던 합성곱 계산은 (4,4) 크기의 입력에 (3,3)크기의 커널을 작용하여 (2,2) 크기의 특성 **맵(필터 하나로 4개 출력)** 을 만들었다. 그런데 만약 커널 크기는 (3,3)으로 그대로 두고 출력의 크기를 입력과 동일하게 (4,4)로 만들려면 어떻게 해야 할까?\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "(4,4) 입력과 동일한 크기의 출력을 만들려면 마치 더 큰 입력에 합성곱하는 척해야 한다. 예를 들어 실제 입력 크기는 (4,4)이지만 (6,6)처럼 다룬다고 가정해 보자. 오른쪽 그림과 같이 (6,6) 크기이면 (3,3) 크기의 커널로 합성곱을 했을 때 출력의 크기가 얼마나 될까?\n",
    "- (3,3) 커널로 도장을 찍어 보면 출력의 크기가 (4,4)가 된다.\n",
    "\n",
    "\n",
    "이렇게 입력 배열의 주위를 가상의 원소로 채우는 것은 **패딩(padding)** 이라고 한다. ***실제 입력값이 아니기 때문에 패딩은 0으로 채운다.*** 즉 (4,4)크기의 입력에 0을 1개 패딩 하면 다음과 같은 (6,6) 크기의 입력이 된다. 패딩의 역할은 순전히 커널이 도장을 찍을 횟수를 늘려주는 것 밖에는 없다. ***실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지는 않는다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2a44a",
   "metadata": {},
   "source": [
    "이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 ***입력 주위에 0으로 패딩 하는 것을 세임 패딩 (same padding)이라고 부른다.*** 합성곱 신경망에서는 세임 패딩이 많이 사용된다. 바꿔 말하면 입력과 특성 맵의 크기를 동일하게 만드는 경우가 아주 많다.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "***패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 밸리드 패딩(valid padding)이라고 한다.*** 밸리드 패딩은 특성 맵의 크기가 줄어들 수밖에 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e2925",
   "metadata": {},
   "source": [
    "\n",
    "그럼 왜 합성곱에서는 패딩을 즐겨 사용할까? 만약 패딩이 없다면 위의 예에서 (4,4) 크기의 입력에 패딩 없이 합성곱을 한다면 왼쪽 위 모서리의 3은 커널 도장에서 딱 한번 찍힌다. **사실 네 모서리에 있는 다른 3개의 값도 마찬가지로 한 번만 찍힘.**\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "반면 다른 원소들은 2번 이상 커널과 계산된다. 가운데 있는 4개 원소 4,8,5,1은 4번의 합성곱 계산에 모두 포한된다. 만약 이 입력을 이미지라고 생각하면 **모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 가능성이 높다.** 반면 가운데 있는 정보는 두드러지게 표현된다.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "적절한 패딩은 이처럼 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와준다. 앞에서도 언급했지만 일반적인 합성곱 신경망에서는 ***세임 패딩이 많이 사용된다.*** 케라스 Conv2D 클래스에서는 padding 매개변수로 패딩을 지정할 수 있다. \n",
    "\n",
    "기본값은 'valid'로 밸리드 패딩을 나타낸다. 세임 패딩을 사용하려면 'same'으로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c0c3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c2294e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef15ec",
   "metadata": {},
   "source": [
    "##### 스트라이드\n",
    "- 여태 본 합성곱은 좌우, 상하로 한 칸씩만 이동함\n",
    "\n",
    "- 하지만 두 번 건너뛸 수도 있다\n",
    "\n",
    "- 이렇게 하면 만들어지는 특성맵의 크기는 더 작아진다.\n",
    "\n",
    "- 기본값 = 1(한칸씩), 하지만 strides 매개변수를 조정하면 바꿀 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70872e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x2c24ebbd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu', padding='same', strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684eef7f",
   "metadata": {},
   "source": [
    "strides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1,1)과 같이 튜플을 사용해 각각 지정할 수 있다.\n",
    "\n",
    "하지만 커널의 이동 크기를 가로세로 방향으로 다르게 지정하는 경우는 거의 없다. \n",
    "\n",
    "또 1보다 큰 스트라이드를 사용하는 경우도 드물다. ***대부분 기본값을 그대로 사용하기 때문에 strides 매개변수는 잘 사용하지 않는다.***\n",
    "\n",
    "스트라이드는 도장(필터)이 이동하는 칸의 개수라고 생각하면 편하다. 튜플로 이동 칸수를 지정할 수 있다.\n",
    "\n",
    "\n",
    "케라스 API를 사용하면 Conv2D 클래스의 옵션으로 간단히 처리 할 수 있다. ***꼭 기억해야 할 것은 세임 패딩의 경우 입력과 만들어진 특성 맵의 가로세로 크기가 같다는 점이다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c486e",
   "metadata": {},
   "source": [
    "### 폴링\n",
    "폴링(pooling)은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. ***하지만 특성맵의 개수는 줄이지 않는다.***\n",
    "\n",
    "예를 들면 다음 그림처럼 (2,2,3) 크기의 특성 맵에 풀링을 적용하면 마지막 차원인 개수는 그대로 유지하고 너비와 높이만 줄어들어 (1,1,3)크기의 특성 맵이 된다.(p.435) -> 마지막 차원이 특성맵의 개수\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "폴링은 특성 맵에 커널(가중치) 없는 필터를 적용하는 것과 비슷하게 생각하자.\n",
    "\n",
    "폴링도 합성곱처럼 입력 위를 지나가면서 도장을 찍는다. 이를 각각 최대 풀링(maxpooling) 과 평균 풀링 (average pooling) 이라고 부른다. \n",
    "\n",
    "풀링은 합성곱 층과 뚜렷이 구분되기 때문에 **풀링 층** 이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8339e5",
   "metadata": {},
   "source": [
    "-풀링 층의 출력도 특성 맵이라고 해야하나?\n",
    "\n",
    "- 맞다. 합성곱 신경망에서는 합성곱 층과 풀링 층에서 출력되는 값을 모두 특성 맵이라고 부른다.\n",
    "\n",
    "풀링은 가중치가 없고 크기와 스트라이드가 같기 때문에 이해하기 쉽다. 또 패딩도 없다. ***케라스에서 MaxPooling2D*** 클래스로 풀링을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab377d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x2c2193490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.MaxPooling2D(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251580e1",
   "metadata": {},
   "source": [
    "MaxPooling2D의 첫 번째 매개변수로 풀링의 크기를 지정한다. 대부분의 풀링의 크기는 2이다. 즉 가로세로 크기를 절반으로 줄인다. 가로세로 방향의 풀링 크기를 다르게 하려면 첫 번째 매개변수를 정수의 튜플로 지정할 수 있다.(예를 들면(2,3)). 하지만 이런 경우는 극히 드물다.\n",
    "\n",
    "\n",
    "합성곱 층과 마찬가지로 strides와 padding 매개변수를 제공한다. **strides의 기본값은 자동으로 풀링의 크기이므로 따로 지정할 필요가없다.** \n",
    "\n",
    "padding의 기본값은 'valid'로 패딩을 하지 않는다. 앞서 언급한 대로 풀링은 패딩을 하지않기 때문에 이 매개변수를 바꾸는 경우는 거의 없다. 예를 들어 바로 이전에 쓴 최대 풀링과 같은 코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2306907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x2c22d5750>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.MaxPooling2D(2, strides=2, padding='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537caffc",
   "metadata": {},
   "source": [
    "평균 풀링을 제공하는 클래스 AveragePooling2D이다. 최댓값 대신 평균을 계산하는 것만 빼면 MaxPooling2D와 동일하며 제공하는 매개변수도 같다. 많은 경우 평균 풀링보다 최대 풀링을 많이 사용한다. 평균 풀링은 특성 맵에 있는 중요한 정보를(평균하여) 희석시킬 수 있기 때문이다.\n",
    "\n",
    "***꼭 기억할 점은 풀링은 가로세로 방향으로만 진행한다. 특성 맵의 개수는 변하지 않고 그대로이다.***\n",
    "\n",
    "이제 합성곱의 중요한 모든 요소를 배웠다. 합성곱 신경망의 전체 구조를 살펴보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897cf2d8",
   "metadata": {},
   "source": [
    "### 합성곱 신경망의 전체 구조\n",
    "지금까지 합성곱 층, 필터, 패딩, 스트라이드, 풀링 등 중요한 합성곱 신경망의 개념을 모두 살펴보았다. 이들을 합쳐서 전체 구조를 그려 보겠다. 예상할 수 있겠지만 합성곱 신경망은 7장에서 처럼 일렬로 늘어선 뉴런으로 표현하기 힘들다. 합성곱 신경망의 입력은 일반적으로 너비와 높이가 있는 이미지이기 때문에 조금 입체적으로 그려보겠다. (p.437)\n",
    "\n",
    "\n",
    "- 풀링을 사용하는 이유는 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문이다. 합성곱 신경망은 이렇게 ***합성곱 층에서 특성맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룬다.***\n",
    "\n",
    "***전체적인 내용은 p.437~***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45744548",
   "metadata": {},
   "source": [
    "1. 풀링(2,2 풀링)을 거친 특성맵 크기는 절반으로 줄어 (2,2, 3)이 되고\n",
    "\n",
    "2. 밀집층에서 이 3차원 배열을 1차원으로 펼친다(Flatten 클래스 사용)\n",
    "\n",
    "3. 출력층에는 3개의 뉴런(즉 3개의 클래스 분류하는 다중분류 문제), 출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9ed50",
   "metadata": {},
   "source": [
    "### 컬러 이미지를 사용한 합성곱\n",
    "\n",
    "지금까지 우리는 입력을 2차원 배열이라고 가정했다. 이 장에서 다룰 패션은 MNIST 데이터는 실제로 흑백 이미지이기 때문에 2차원 배열로 표현할 수 있다. 하지만 컬러 이미지라면 어떨까? 컬러이미지는 RGB(빨강, 초록, 파랑) 채널로 구성되어 있기 때문에 컴퓨터는 이를 3차원 배열로 표시한다.**(p.438~ 자세한 설명 보기)**\n",
    "\n",
    "합성곱 신경망에서 필터는 이미지에 있는 어떤 특징을 찾는다고 생각 할 수 있다. 처음에는 간단한 기본적인 특징(직선, 곡선 등)을 찾고 층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘린다. 또 어떤 특징이 이미지의 어느 위치에 놓이더라고 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄여가는 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d52fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
