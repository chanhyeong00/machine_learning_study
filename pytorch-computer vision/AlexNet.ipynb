{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR966PNsPUFpxL7ZoMSxZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanhyeong00/machine_learning_study/blob/main/pytorch-computer%20vision/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "PujnOkDunM56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torchinfo 라이브러리로 모델 구조 확인\n",
        "\n",
        "모델과 입력데이터를 전달했을 때 각 계층의 출력 형태와 매개변수를 확인할 수 있다.\n",
        "\n",
        "모델에 입력하는 텐서 데이터의 형태에 따라 출력 형태가 바뀐다"
      ],
      "metadata": {
        "id": "fpEwndeynWD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-kIX8vqnrk5",
        "outputId": "ff7d8d74-2842-47bf-80ab-dec9dd5914de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ep3m_CcknD",
        "outputId": "f0ad256e-7c9a-4d2a-ebb6-48eeebf5799e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 96.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "AlexNet                                  [1, 1000]                 --\n",
              "├─Sequential: 1-1                        [1, 256, 6, 6]            --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n",
              "│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n",
              "│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n",
              "│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n",
              "│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n",
              "│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n",
              "│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n",
              "│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n",
              "│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n",
              "│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n",
              "│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n",
              "│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n",
              "│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n",
              "├─Sequential: 1-3                        [1, 1000]                 --\n",
              "│    └─Dropout: 2-14                     [1, 9216]                 --\n",
              "│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n",
              "│    └─ReLU: 2-16                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-17                     [1, 4096]                 --\n",
              "│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-19                        [1, 4096]                 --\n",
              "│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n",
              "==========================================================================================\n",
              "Total params: 61,100,840\n",
              "Trainable params: 61,100,840\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 714.68\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 3.95\n",
              "Params size (MB): 244.40\n",
              "Estimated Total Size (MB): 248.96\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from torchvision import models\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "model = models.alexnet(weights=\"AlexNet_Weights.IMAGENET1K_V1\")\n",
        "# 사전학습된 알렉스넷 모델 가중치 불러오기\n",
        "# None 으로 설정하면 사전학습된 가중치 불러오지 않음\n",
        "summary(model, (1, 3, 224, 224), device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력 결과는 알렉스넷에 (1, 3, 224, 224) 크기의 텐서를 입력했을 때 계층마다 출력하는 특징 맵의 크기와 필요한 매개변수의 수를 보여준다."
      ],
      "metadata": {
        "id": "vlJhbB5urfJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지넷으로 사전 학습된 알렉스넷 모델이다. 이미지넷은 1,000 개의 클래스로 구성된 데이터세트이므로 사전 학습된 알렉스넷은 1,000개의 클래스에 대한 예측을 수행"
      ],
      "metadata": {
        "id": "PMS6iWFGsL6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 클래스 정보 불러오기"
      ],
      "metadata": {
        "id": "2OL0Aq1fsbPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"imagenet_classes.txt\", 'r') as file:\n",
        "  classes = file.read().splitlines()\n",
        "\n",
        "print(f\"클래스 개수 : {len(classes)}\")\n",
        "print(f\"첫 번째 클래스 레이블 : {classes[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWYGNyEMnYxB",
        "outputId": "ac18690b-1a00-4382-b96a-25d8546dbee6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 개수 : 1000\n",
            "첫 번째 클래스 레이블 : tench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 데이터 전처리"
      ],
      "metadata": {
        "id": "n1o5HkOKs8DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean = [0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        ) # 이미지는 3차원이므로 3개(이미지넷 데이터세트에서 사용된 이미지들 평균과 표준편차 값)\n",
        "    ]\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "model = models.alexnet(weights=\"AlexNet_Weights.IMAGENET1K_V1\").eval().to(device)\n",
        "\n",
        "tensors = []\n",
        "files = ['bus.jpg', 'airplane.jpg']\n",
        "\n",
        "for file in files:\n",
        "  image = Image.open(file)\n",
        "  tensors.append(transform(image))\n",
        "\n",
        "tensors = torch.stack(tensors)\n",
        "print(f\"입력 텐서의 크기: {tensors.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LrTm63Is9LK",
        "outputId": "92cec62d-a9fb-422b-ece7-4f1c090f9c7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텐서의 크기: torch.Size([2, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 추론"
      ],
      "metadata": {
        "id": "rd3p03qWu1uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(tensors.to(device)) # 순전파 수행, 출력값은 입력텐서의 배치 크기와 동일([배치크기, 클래스 개수])\n",
        "  print(outputs)\n",
        "  probs = F.softmax(outputs, dim=-1) # 소프트맥스 함수로 값을 활성화\n",
        "  print(probs)\n",
        "  top_probs, top_idxs = probs.topk(5) # topk 메서드로 텐서 값이 가장 큰 상위 다섯개 요소 반환\n",
        "\n",
        "# 확률, 인덱스, 클래스를 넘파이 배열로 변환\n",
        "top_probs = top_probs.detach().cpu().numpy()\n",
        "top_idxs = top_idxs.detach().cpu().numpy()\n",
        "top_classes = np.array(classes)[top_idxs]\n",
        "\n",
        "for idx, (cls, prob) in enumerate(zip(top_classes, top_probs)):\n",
        "    print(f\"{files[idx]} 추론 결과\")\n",
        "    for c, p in zip(cls, prob):\n",
        "        print(f\" - {c:<30} : {p * 100:>5.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l_T76B2t2YU",
        "outputId": "c20641a2-a65a-4165-8670-cd24e18de298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.0288, -0.1984,  2.1301,  ..., -5.3826, -2.6092,  1.2260],\n",
            "        [-0.0914, -4.3196,  2.9599,  ..., -1.7398,  4.6348, -1.3781]])\n",
            "tensor([[3.4603e-13, 1.5946e-11, 1.6365e-10,  ..., 8.9371e-14, 1.4311e-12,\n",
            "         6.6264e-11],\n",
            "        [7.5438e-10, 1.0998e-11, 1.5949e-08,  ..., 1.4511e-10, 8.5144e-08,\n",
            "         2.0836e-10]])\n",
            "bus.jpg 추론 결과\n",
            " - streetcar                      : 60.25%\n",
            " - trolleybus                     : 37.99%\n",
            " - minibus                        :  1.54%\n",
            " - passenger car                  :  0.17%\n",
            " - recreational vehicle           :  0.03%\n",
            "airplane.jpg 추론 결과\n",
            " - airliner                       : 66.83%\n",
            " - warplane                       : 20.12%\n",
            " - wing                           :  9.29%\n",
            " - space shuttle                  :  2.89%\n",
            " - missile                        :  0.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과를 보면 bus는 streetcar 나 trolleybus로 예측\n",
        "\n",
        "비행기는 airliner이나 warplane로 유사한 클래스가 가장 높게 예측된다."
      ],
      "metadata": {
        "id": "tQYhxqY13Pcw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6mbmhcxxtHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}