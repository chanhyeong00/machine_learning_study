{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqKQbbKnxzC1625/axiY8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanhyeong00/machine_learning_study/blob/main/%08Pytorch/basic_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%84%B8%ED%8A%B8_%EB%B6%84%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4-Cn2Hl2nLs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        self.x = df.iloc[:, 0].values\n",
        "        self.y = df.iloc[:, 1].values\n",
        "        self.length = len(df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
        "        y = torch.FloatTensor([self.y[index]])\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "metadata": {
        "id": "NZjiDLlMIeVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YMfqAVBFIiir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋이 없어서 코드만"
      ],
      "metadata": {
        "id": "1FdOjzRMJNTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(\"../datasets/non_linear.csv\")\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "validation_size = int(dataset_size * 0.1)\n",
        "test_size = dataset_size - train_size - validation_size\n",
        "# 여기서 random_split으로 훈련, 검증, 테스트 세트 분리\n",
        "# 분리된 데이터셋의 개수의 합은 데이터셋 데이터 개수와 같아야 한다.\n",
        "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
        "print(f\"Training Data Size : {len(train_dataset)}\")\n",
        "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
        "print(f\"Testing Data Size : {len(test_dataset)}\")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "wrmtGSldIlnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "KvcdkDZqIo8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    cost = 0.0\n",
        "\n",
        "    for x, y in train_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cost += loss\n",
        "\n",
        "    cost = cost / len(train_dataloader)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "id": "mpWavlmxIo-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for x, y in validation_dataloader: # 훈련후 검증세트로 모델 평가\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(x)\n",
        "        print(f\"X : {x}\")\n",
        "        print(f\"Y : {y}\")\n",
        "        print(f\"Outputs : {outputs}\")\n",
        "        print(\"--------------------\")"
      ],
      "metadata": {
        "id": "O58dKB18IyLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}