{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1fsmxXsyUfl5hKLbQYi0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanhyeong00/machine_learning_study/blob/main/%08Pytorch/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단순 선형 회귀: 넘파이"
      ],
      "metadata": {
        "id": "b9YpB1y4R8Qn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtqviGI9Rzt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array(\n",
        "    [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
        "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
        "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]]\n",
        ")\n",
        "y = np.array(\n",
        "    [[0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
        "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
        "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = 0.0\n",
        "bias = 0.0\n",
        "learning_rate = 0.005"
      ],
      "metadata": {
        "id": "dfwqNoXnSAwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    y_hat = weight * x + bias # 가설(hypothesis)\n",
        "\n",
        "    # mean()을 사용해 하나로 묶음(batch 적용)\n",
        "    # -> 여기서는 데이터 크기인 30이 된다.(30 * 10,000이지만 30개를 묶어서 10,000번만)\n",
        "\n",
        "    cost = ((y - y_hat) ** 2).mean() # 손실(loss)\n",
        "\n",
        "    # W_i+1 = W_i - a(lr) * E[(Y_hat - y_i) * x] -> 가중치 함수(책 68p)\n",
        "    weight = weight - learning_rate * ((y_hat - y) * x).mean() # 가중치\n",
        "\n",
        "    # 이건 책 68p에서 bias에 대해서 편미분 진행\n",
        "    bias = bias - learning_rate * (y_hat - y).mean() # b(편향)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight:.3f}, Bias : {bias:.3f}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukWYGlwKSCd-",
        "outputId": "51c73bb8-cd75-4c61-b8ff-954387636c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000, Weight : 0.872, Bias : -0.290, Cost : 1.377\n",
            "Epoch : 2000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
            "Epoch : 3000, Weight : 0.878, Bias : -0.422, Cost : 1.372\n",
            "Epoch : 4000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n",
            "Epoch : 5000, Weight : 0.879, Bias : -0.435, Cost : 1.372\n",
            "Epoch : 6000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
            "Epoch : 7000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
            "Epoch : 8000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
            "Epoch : 9000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
            "Epoch : 10000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 설정된 옵션에서 6,000번 정도 학습했을 때 더이상 오차가 감소하지 않는다.\n",
        "\n",
        "초깃값 설정 등 학습에 영향을 많이 끼친다.\n",
        "\n",
        "그러므로 적절하지 않은 초깃값을 할당했을 때 하이퍼파라미터 튜닝을 진행하고 이를 통해 원할한 학습 진행 가능"
      ],
      "metadata": {
        "id": "elppz7obVIP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단순 선형 회귀: 파이토치"
      ],
      "metadata": {
        "id": "yjaB0dmKViHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "SQM_ntvGSMjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([\n",
        "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
        "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
        "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
        "])\n",
        "y = torch.FloatTensor([\n",
        "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
        "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
        "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
        "])"
      ],
      "metadata": {
        "id": "nwQz5hCDVqzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**하이퍼 파라미터 초기화**"
      ],
      "metadata": {
        "id": "rHbOepwxV5ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.zeros(1, requires_grad=True)\n",
        "bias = torch.zeros(1, requires_grad=True)\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "mT0BsndVVq7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([weight, bias], lr=learning_rate)"
      ],
      "metadata": {
        "id": "g7K5FOakXUKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    hypothesis = weight * x + bias\n",
        "    cost = torch.mean((hypothesis - y) ** 2)\n",
        "\n",
        "    optimizer.zero_grad() # optimizer 변수에 포함시킨 매개변수들의 기울기를 0으로 초기화\n",
        "    # weight += x 로 축적되어 저장됨(중복연산 방지)\n",
        "\n",
        "    cost.backward() # 역전파(back propagation) 수행. 매개변수들의 기울기가 새로 계산된다\n",
        "    optimizer.step() # 최적화 함수에 반영. lr 값을 반영한 확률적 경사하강법 연산이 적용된다.\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight.item():.3f}, Bias : {bias.item():.3f}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhzdBgBjXad3",
        "outputId": "3dd5113c-1da5-46de-fcab-8fc8d415246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000, Weight : 0.864, Bias : -0.138, Cost : 1.393\n",
            "Epoch : 2000, Weight : 0.870, Bias : -0.251, Cost : 1.380\n",
            "Epoch : 3000, Weight : 0.873, Bias : -0.321, Cost : 1.375\n",
            "Epoch : 4000, Weight : 0.875, Bias : -0.364, Cost : 1.373\n",
            "Epoch : 5000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
            "Epoch : 6000, Weight : 0.878, Bias : -0.408, Cost : 1.372\n",
            "Epoch : 7000, Weight : 0.878, Bias : -0.419, Cost : 1.372\n",
            "Epoch : 8000, Weight : 0.878, Bias : -0.425, Cost : 1.372\n",
            "Epoch : 9000, Weight : 0.879, Bias : -0.429, Cost : 1.372\n",
            "Epoch : 10000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "넘파이와 동일하게 수렴되는 것을 볼 수 있다.\n",
        "\n",
        "학습률은 0.001로 기존 경사 하강법보다 낮은 학습률을 사용하지만,\n",
        "\n",
        "SGD(Stochastic Gradient Descent), 확률적경사하강법을 활용해 더 빠른 속도로 최적의 가중치와 편향을 찾았다."
      ],
      "metadata": {
        "id": "k_SceMMwYfN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero_grad(), cost.backward(), optimizer.step() 알아보기"
      ],
      "metadata": {
        "id": "vLl9jzauZXZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "x = torch.FloatTensor([\n",
        "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
        "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
        "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
        "])\n",
        "y = torch.FloatTensor([\n",
        "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
        "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
        "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
        "])\n",
        "\n",
        "weight = torch.zeros(1, requires_grad=True)\n",
        "bias = torch.zeros(1, requires_grad=True)\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = optim.SGD([weight, bias], lr=learning_rate)\n",
        "\n",
        "for epoch in range(10000):\n",
        "    hypothesis = weight * x + bias\n",
        "    cost = torch.mean((hypothesis - y) ** 2)\n",
        "\n",
        "    print(f\"Epoch : {epoch+1:4d}\") # 토치 텐서에는 grad가 있다.\n",
        "    print(f\"Step [1] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
        "\n",
        "    optimizer.zero_grad() # 옵티마이저 기울기 초기화\n",
        "    print(f\"Step [2] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
        "\n",
        "    cost.backward() # 역전파 수행해서 기울기 계산(weight에는 반영되지 않음)\n",
        "    print(f\"Step [3] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
        "\n",
        "    optimizer.step() # 위에서 계산한 weight 변수에 반영한다.\n",
        "    print(f\"Step [4] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
        "\n",
        "    if epoch == 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hcghNHXYcr4",
        "outputId": "1958effa-7798-4ede-c8ac-03976ad38781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :    1\n",
            "Step [1] : Gradient : None, Weight : 0.00000\n",
            "Step [2] : Gradient : None, Weight : 0.00000\n",
            "Step [3] : Gradient : tensor([-540.4854]), Weight : 0.00000\n",
            "Step [4] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
            "Epoch :    2\n",
            "Step [1] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
            "Step [2] : Gradient : None, Weight : 0.54049\n",
            "Step [3] : Gradient : tensor([-198.9818]), Weight : 0.54049\n",
            "Step [4] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
            "Epoch :    3\n",
            "Step [1] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
            "Step [2] : Gradient : None, Weight : 0.73947\n",
            "Step [3] : Gradient : tensor([-73.2604]), Weight : 0.73947\n",
            "Step [4] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
            "Epoch :    4\n",
            "Step [1] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
            "Step [2] : Gradient : None, Weight : 0.81273\n",
            "Step [3] : Gradient : tensor([-26.9772]), Weight : 0.81273\n",
            "Step [4] : Gradient : tensor([-26.9772]), Weight : 0.83970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 신경망 패키지"
      ],
      "metadata": {
        "id": "igaWVO6qdKZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "nQhXUBPxZdrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor([\n",
        "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
        "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
        "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
        "])\n",
        "y = torch.FloatTensor([\n",
        "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
        "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
        "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
        "])"
      ],
      "metadata": {
        "id": "aZsN-kikdbaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(1, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "5X_2v-Jidd2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    output = model(x)\n",
        "    cost = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUsthcMdfh7",
        "outputId": "1fd1524f-c661-41da-9732-f4015bc60d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000, Model : [Parameter containing:\n",
            "tensor([[0.8707]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2684], requires_grad=True)], Cost : 1.379\n",
            "Epoch : 2000, Model : [Parameter containing:\n",
            "tensor([[0.8738]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.3317], requires_grad=True)], Cost : 1.375\n",
            "Epoch : 3000, Model : [Parameter containing:\n",
            "tensor([[0.8757]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.3711], requires_grad=True)], Cost : 1.373\n",
            "Epoch : 4000, Model : [Parameter containing:\n",
            "tensor([[0.8769]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.3956], requires_grad=True)], Cost : 1.373\n",
            "Epoch : 5000, Model : [Parameter containing:\n",
            "tensor([[0.8777]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4108], requires_grad=True)], Cost : 1.372\n",
            "Epoch : 6000, Model : [Parameter containing:\n",
            "tensor([[0.8781]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4203], requires_grad=True)], Cost : 1.372\n",
            "Epoch : 7000, Model : [Parameter containing:\n",
            "tensor([[0.8784]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4262], requires_grad=True)], Cost : 1.372\n",
            "Epoch : 8000, Model : [Parameter containing:\n",
            "tensor([[0.8786]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4299], requires_grad=True)], Cost : 1.372\n",
            "Epoch : 9000, Model : [Parameter containing:\n",
            "tensor([[0.8787]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4322], requires_grad=True)], Cost : 1.372\n",
            "Epoch : 10000, Model : [Parameter containing:\n",
            "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4336], requires_grad=True)], Cost : 1.372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다중 선형 회귀"
      ],
      "metadata": {
        "id": "UXtsUwwmfYMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "train_x = torch.FloatTensor([\n",
        "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
        "]) # (n,2), 독립변수 두개\n",
        "train_y = torch.FloatTensor([\n",
        "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
        "]) # 다중회귀를 위해 (n,2) 형태로 입력"
      ],
      "metadata": {
        "id": "9wXpHlsUeSD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorDataset은 기본 Dataset 클래스를 상속받아 재정의된 클래스이다."
      ],
      "metadata": {
        "id": "tBcicsUDf3uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
        "# 배치 크기 조절, 셔플(데이터 순서 변경),\n",
        "# drop_last: 배치제거(배치 크기에 맞지 않는 배치를 제거) -> 불완전한 배치를 사용할지 말지를 정함"
      ],
      "metadata": {
        "id": "332nFzQhfzOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(2, 2, bias=True)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "1p45UH8ggyeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20000):\n",
        "    cost = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        x, y = batch # 배치\n",
        "        output = model(x) # 예측\n",
        "\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        optimizer.zero_grad() # 기울기 초기화\n",
        "        loss.backward() # 역전파 수행(기울기 계산)\n",
        "        optimizer.step() # 옵티마이저에 weight 반영\n",
        "\n",
        "        cost += loss\n",
        "\n",
        "    cost = cost / len(train_dataloader) # 손실\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olCQUJNXhGJd",
        "outputId": "49e7fd6a-59a1-4d8f-a496-49a6bf871378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000, Model : [Parameter containing:\n",
            "tensor([[0.5812, 0.2188],\n",
            "        [0.8209, 0.3467]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.5974,  0.4114], requires_grad=True)], Cost : 0.047\n",
            "Epoch : 2000, Model : [Parameter containing:\n",
            "tensor([[0.6828, 0.1662],\n",
            "        [0.9554, 0.2770]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.7515,  0.2072], requires_grad=True)], Cost : 0.012\n",
            "Epoch : 3000, Model : [Parameter containing:\n",
            "tensor([[0.7345, 0.1394],\n",
            "        [1.0240, 0.2415]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.8301,  0.1032], requires_grad=True)], Cost : 0.003\n",
            "Epoch : 4000, Model : [Parameter containing:\n",
            "tensor([[0.7609, 0.1258],\n",
            "        [1.0589, 0.2235]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.8701,  0.0503], requires_grad=True)], Cost : 0.001\n",
            "Epoch : 5000, Model : [Parameter containing:\n",
            "tensor([[0.7744, 0.1189],\n",
            "        [1.0767, 0.2143]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.8905,  0.0233], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 6000, Model : [Parameter containing:\n",
            "tensor([[0.7812, 0.1153],\n",
            "        [1.0858, 0.2096]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9009,  0.0095], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 7000, Model : [Parameter containing:\n",
            "tensor([[0.7847, 0.1135],\n",
            "        [1.0904, 0.2073]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9062,  0.0025], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 8000, Model : [Parameter containing:\n",
            "tensor([[0.7865, 0.1126],\n",
            "        [1.0928, 0.2060]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9089, -0.0011], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 9000, Model : [Parameter containing:\n",
            "tensor([[0.7874, 0.1121],\n",
            "        [1.0940, 0.2054]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9102, -0.0029], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 10000, Model : [Parameter containing:\n",
            "tensor([[0.7879, 0.1119],\n",
            "        [1.0946, 0.2051]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9109, -0.0038], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 11000, Model : [Parameter containing:\n",
            "tensor([[0.7881, 0.1118],\n",
            "        [1.0949, 0.2049]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9113, -0.0043], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 12000, Model : [Parameter containing:\n",
            "tensor([[0.7882, 0.1117],\n",
            "        [1.0950, 0.2049]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9115, -0.0045], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 13000, Model : [Parameter containing:\n",
            "tensor([[0.7883, 0.1117],\n",
            "        [1.0951, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0047], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 14000, Model : [Parameter containing:\n",
            "tensor([[0.7883, 0.1117],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0047], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 15000, Model : [Parameter containing:\n",
            "tensor([[0.7883, 0.1117],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0047], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 16000, Model : [Parameter containing:\n",
            "tensor([[0.7883, 0.1117],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0048], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 17000, Model : [Parameter containing:\n",
            "tensor([[0.7883, 0.1117],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0048], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 18000, Model : [Parameter containing:\n",
            "tensor([[0.7884, 0.1116],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0048], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 19000, Model : [Parameter containing:\n",
            "tensor([[0.7884, 0.1116],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0048], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 20000, Model : [Parameter containing:\n",
            "tensor([[0.7884, 0.1116],\n",
            "        [1.0952, 0.2048]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.9116, -0.0048], requires_grad=True)], Cost : 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**편향 제거**"
      ],
      "metadata": {
        "id": "wjq9EK3EiTUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(2, 2, bias=False)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "IU8cDmzohgVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20000):\n",
        "    cost = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        x, y = batch\n",
        "        output = model(x)\n",
        "\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cost += loss\n",
        "\n",
        "    cost = cost / len(train_dataloader)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JLtfSriiVsm",
        "outputId": "d863dae8-1af7-4598-a022-e9c825766b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000, Model : [Parameter containing:\n",
            "tensor([[0.4822, 0.1852],\n",
            "        [0.9144, 0.3502]], requires_grad=True)], Cost : 0.097\n",
            "Epoch : 2000, Model : [Parameter containing:\n",
            "tensor([[ 0.7321, -0.0170],\n",
            "        [ 0.9524,  0.3194]], requires_grad=True)], Cost : 0.061\n",
            "Epoch : 3000, Model : [Parameter containing:\n",
            "tensor([[ 0.9306, -0.1778],\n",
            "        [ 0.9827,  0.2948]], requires_grad=True)], Cost : 0.038\n",
            "Epoch : 4000, Model : [Parameter containing:\n",
            "tensor([[ 1.0886, -0.3055],\n",
            "        [ 1.0068,  0.2754]], requires_grad=True)], Cost : 0.024\n",
            "Epoch : 5000, Model : [Parameter containing:\n",
            "tensor([[ 1.2141, -0.4070],\n",
            "        [ 1.0259,  0.2599]], requires_grad=True)], Cost : 0.015\n",
            "Epoch : 6000, Model : [Parameter containing:\n",
            "tensor([[ 1.3138, -0.4877],\n",
            "        [ 1.0411,  0.2476]], requires_grad=True)], Cost : 0.010\n",
            "Epoch : 7000, Model : [Parameter containing:\n",
            "tensor([[ 1.3930, -0.5518],\n",
            "        [ 1.0532,  0.2378]], requires_grad=True)], Cost : 0.006\n",
            "Epoch : 8000, Model : [Parameter containing:\n",
            "tensor([[ 1.4561, -0.6027],\n",
            "        [ 1.0628,  0.2301]], requires_grad=True)], Cost : 0.004\n",
            "Epoch : 9000, Model : [Parameter containing:\n",
            "tensor([[ 1.5062, -0.6432],\n",
            "        [ 1.0704,  0.2239]], requires_grad=True)], Cost : 0.002\n",
            "Epoch : 10000, Model : [Parameter containing:\n",
            "tensor([[ 1.5459, -0.6754],\n",
            "        [ 1.0765,  0.2190]], requires_grad=True)], Cost : 0.002\n",
            "Epoch : 11000, Model : [Parameter containing:\n",
            "tensor([[ 1.5775, -0.7010],\n",
            "        [ 1.0813,  0.2151]], requires_grad=True)], Cost : 0.001\n",
            "Epoch : 12000, Model : [Parameter containing:\n",
            "tensor([[ 1.6027, -0.7213],\n",
            "        [ 1.0852,  0.2120]], requires_grad=True)], Cost : 0.001\n",
            "Epoch : 13000, Model : [Parameter containing:\n",
            "tensor([[ 1.6227, -0.7375],\n",
            "        [ 1.0882,  0.2095]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 14000, Model : [Parameter containing:\n",
            "tensor([[ 1.6385, -0.7503],\n",
            "        [ 1.0906,  0.2076]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 15000, Model : [Parameter containing:\n",
            "tensor([[ 1.6511, -0.7605],\n",
            "        [ 1.0926,  0.2060]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 16000, Model : [Parameter containing:\n",
            "tensor([[ 1.6612, -0.7686],\n",
            "        [ 1.0941,  0.2048]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 17000, Model : [Parameter containing:\n",
            "tensor([[ 1.6691, -0.7751],\n",
            "        [ 1.0953,  0.2038]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 18000, Model : [Parameter containing:\n",
            "tensor([[ 1.6755, -0.7802],\n",
            "        [ 1.0963,  0.2030]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 19000, Model : [Parameter containing:\n",
            "tensor([[ 1.6805, -0.7842],\n",
            "        [ 1.0970,  0.2024]], requires_grad=True)], Cost : 0.000\n",
            "Epoch : 20000, Model : [Parameter containing:\n",
            "tensor([[ 1.6845, -0.7875],\n",
            "        [ 1.0976,  0.2019]], requires_grad=True)], Cost : 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coYSehFbiYYh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
